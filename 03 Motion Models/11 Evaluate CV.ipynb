{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef3642-a503-4ab2-8225-66cf818e49aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a1f98-70df-420d-94c0-227943e993d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef848e20-d866-402f-9772-ec7ee3efc081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "from tracking_v2.target import ConstantVelocityTarget\n",
    "from tracking_v2.kalman import LinearKalmanFilter\n",
    "from tracking_v2.motion import ConstantVelocityModel, ConstantAccelerationModel, SingerAccelerationModel\n",
    "from tracking_v2.sensor import GeometricSensor\n",
    "from tracking_v2.evaluation import Runner, run_many, evaluate_many, plot_nees, evaluate_nees, plot_error\n",
    "\n",
    "from tracking.util import to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e5c47-29b5-4ec7-aa58-3c01b8034fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def two_columns(fig1, fig2):\n",
    "    output1 = widgets.Output(layout={'width': '50%'})\n",
    "    with output1:\n",
    "        display(fig1)\n",
    "\n",
    "    output2 = widgets.Output(layout={'width': '50%'})\n",
    "    with output2:\n",
    "        display(fig2)\n",
    "    \n",
    "    column_layout = widgets.HBox([output1, output2])\n",
    "    display(column_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5a9e1-9e26-4a55-b3e5-98de8f7c4147",
   "metadata": {},
   "source": [
    "# Target and sensor\n",
    "\n",
    "In this document we will consider a simple target moving with constant velocity along the X axis. The sensor produces 3D measurement in the Cartesian space with unit covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0487b21-397d-4501-aa3a-131523cb70f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = ConstantVelocityTarget()\n",
    "sensor = GeometricSensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b91cb00-8dff-4d9b-9a19-dad0b182543f",
   "metadata": {},
   "source": [
    "# Kalman Filter drift\n",
    "\n",
    "In some situations, Kalman Filter's error has the tendency to drift - accumulate over time to large values of NEES.\n",
    "\n",
    "Our target is moving with a perfectly constant velocity. The appropriate motion noise model would be of no noise, $Q = 0$. However, this leads to state covariance $\\hat{P}$ converging to zero which places majority of \"trust\" into the current state estimate and increasingly less into each new measurement. With incorrect velocity estimates, this can push the state estimate to be quite off while the expected variance is minuscule.\n",
    "\n",
    "Let's compare two situations: a KF with zero process noise and another with CV motion model with noise set to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb2ed0-522d-44f1-8d5a-89cb17b6f051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _drift(q):\n",
    "    motion = ConstantVelocityModel(q)\n",
    "    kf = LinearKalmanFilter(motion, [[1, 0, 0, 0, 0, 0],\n",
    "                                     [0, 1, 0, 0, 0, 0],\n",
    "                                     [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "    sensor = GeometricSensor(seed=8)\n",
    "    r = Runner(target, sensor, kf)\n",
    "    r.run_many(1, 500)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6de2aa-8f03-4ecb-a3c7-cbdafbd1fa40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r0 = _drift(0)\n",
    "r1 = _drift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9682d1-d383-433b-80e1-23209279ef21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _plot_error(runner):\n",
    "    tm  = np.arange(runner.n-100).reshape((runner.n-100, -1))\n",
    "    err = np.hstack((tm, np.abs(runner.one_x_hat[100:,:3,0] - runner.truth[101:,:3])))\n",
    "    err = to_df(err, columns=['time', 'x', 'y', 'z']).melt(['time'], ['x', 'y', 'z'], 'dim', 'error')\n",
    "    return ex.line(err, x='time', y='error', facet_row='dim')\n",
    "\n",
    "two_columns(_plot_error(r0), _plot_error(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b385b2-6ade-4290-9e01-b77b630aeb58",
   "metadata": {},
   "source": [
    "In the left-hand-side plot above, the absolute error accumulates up to about $0.5$ while in the right-hand-side plot the error does not show the pattern of accumulation, even though it consistently reaches much higher values, up to about $4$. However, the apparent advantage of the model with $Q=0$ disappears once we look at normalized errors (NEES)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a8f40-c092-4936-ab62-b8a59e55177b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _plot_nees(runner):\n",
    "    nees = evaluate_nees(runner.one_x_hat[:, :3, :], runner.one_P_hat[:, :3, :3], runner.truth[1:, :3])\n",
    "    err = np.asarray((np.arange(runner.n-100), nees.scores[100:])).T\n",
    "    err = to_df(err, columns=['time', 'nees'])\n",
    "    fig = ex.line(err, x='time', y='nees')\n",
    "    \n",
    "    ci = sp.stats.chi2.ppf([0.025, 0.975], nees.dim)\n",
    "    fig.add_hline(y=ci[0], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.add_hline(y=ci[1], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "two_columns(_plot_nees(r0), _plot_nees(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fef5f5-4ea7-4649-964c-691f44f0a2c9",
   "metadata": {},
   "source": [
    "Using non-zero process noise (right-hand-side above) leads to NEES scores which do not show the tendency to accumulate over time. They also seem to remain within the 95% confidence interval. This comes at the cost of statistical consistency of the filter: the mean of multiple independent runs of the filter (with different random seeds governing the measurement noise) falls within the predicted 95% confidence interval for $Q=1$ but falls well below it for $Q=1$.\n",
    "\n",
    "Using zero proces (left-hand-side above) leads to covariance estimate converging to zero which exacerbates the non-scaled error and takes it from $0.4$ (meters) to almost 20 (standard deviations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1341f48-649d-40c7-947a-d85e87d48449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drift_many(Q):\n",
    "    motion = ConstantVelocityModel(Q)\n",
    "    kf = LinearKalmanFilter(motion, [[1, 0, 0, 0, 0, 0],\n",
    "                                     [0, 1, 0, 0, 0, 0],\n",
    "                                     [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "    r = Runner(target, sensor, kf)\n",
    "    r.run_many(100, 500)\n",
    "    return r\n",
    "\n",
    "r0 = _drift_many(0)\n",
    "r1 = _drift_many(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3707f6d-12b4-442b-8c64-39b3b10f6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_nees(runner):\n",
    "    nees = evaluate_nees(runner.many_x_hat[:, :, :3, :], runner.many_P_hat[:, :, :3, :3], runner.truth[1:, :3])\n",
    "    err = np.asarray((np.arange(runner.n-100), nees.scores[:,100:].mean(axis=0))).T\n",
    "    err = to_df(err, columns=['time', 'nees'])\n",
    "    fig = ex.line(err, x='time', y='nees')\n",
    "    \n",
    "    ci = sp.stats.chi2.ppf([0.025, 0.975], runner.m * nees.dim) / runner.m\n",
    "    fig.add_hline(y=ci[0], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.add_hline(y=ci[1], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "two_columns(_plot_nees(r0), _plot_nees(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515b951-5359-47f2-a40b-86b0e09d1181",
   "metadata": {},
   "source": [
    "Let's compare that with non-scaled error values. Above we have mean NEES across time from 100 independent runs. With $Q=0$ (on the left) we observe statistical consistency - the mean NEES stays within the 95% confidence interval about 95% of the time. In comparison, with $Q=1$ (on the right) that mean NEES stays below the 95% CI 100% of the time. Thus, the filter is no longer statistically consistent but the covariance estimate better represents the actual error of the position estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9dd314-5899-4fc7-8a3d-4d0f8d1deaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_error(runner):\n",
    "    tm  = np.arange(runner.n-100)\n",
    "    err = np.linalg.norm(runner.many_x_hat[:,100:,:3,0] - runner.truth[101:,:3], axis=2)\n",
    "    \n",
    "    avg = np.array((tm, err.mean(axis=0))).T\n",
    "    avg = to_df(avg, columns=['time', 'err'])\n",
    "    avg['type'] = 'avg'\n",
    "    \n",
    "    low = np.array((tm, np.quantile(err, .025, axis=0))).T\n",
    "    low = to_df(low, columns=['time', 'err'])\n",
    "    low['type'] = '.025'\n",
    "    \n",
    "    upp = np.array((tm, np.quantile(err, .975, axis=0))).T\n",
    "    upp = to_df(upp, columns=['time', 'err'])\n",
    "    upp['type'] = '.975'\n",
    "\n",
    "    err = pd.concat((avg, low, upp), axis=0).melt(['time', 'type'], ['err'], 'dim', 'error')\n",
    "    return ex.line(err, x='time', y='error', color='type', facet_row='dim')\n",
    "\n",
    "two_columns(_plot_error(r0), _plot_error(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdbbff-c0e7-4963-af35-0a64a95b7081",
   "metadata": {},
   "source": [
    "As we see above, for $Q=0$:\n",
    "* `+` the average NEES across multiple runs is consistent with the predicted 95% confidence interval\n",
    "* `+` the non-scaled error is low\n",
    "* `-` NEES on individual runs can accumulate to very large values - above 15 - which means that a tracker might report fairly correct position but with extremely incorrect covariance\n",
    "\n",
    "Coversely, for $Q=1$:\n",
    "* `-` the average NEES across multiple runs is inconsistent with the predicted 95% CI\n",
    "* `-` the non-scaled error is high\n",
    "* `+` the error reported for individual runs matches the actual error much better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a271f3-311a-44b4-9a8f-e6549b5ef14a",
   "metadata": {},
   "source": [
    "As the last thing, let's take a look at the scaled (NEES) and non-scaled (linear) error in the function of process noise intensity $Q$. For each value of $Q$ we perform 100 independent runs of the Kalman Filter, each taking 500 iterations. We then calcuate the mean and the 0.975 quantile of NEES and non-scaled errors for each iteration, across all 100 independent runs. Below, you can see boxplots of those four metrics: each boxplot aggregates 400 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123527b9-cbfd-401d-844b-9cd9c341d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for Q in [0, .001, .002, .005, .01, .02, .05, .1, .2, .5, 1, 1.5, 2, 2.5, 5, 10, 20]:\n",
    "    run  = _drift_many(Q)\n",
    "    nees = evaluate_nees(run.many_x_hat[:, 100:, :3, :], run.many_P_hat[:, 100:, :3, :3], run.truth[101:, :3])\n",
    "    err  = np.linalg.norm(run.many_x_hat[:,100:,:3,0] - run.truth[101:,:3], axis=2)\n",
    "    \n",
    "    mean_nees = nees.scores.mean(axis=0)\n",
    "    q975_nees = np.quantile(nees.scores, .975, axis=0)\n",
    "\n",
    "    mean_err = err.mean(axis=0)\n",
    "    q975_err = np.quantile(err, .975, axis=0)\n",
    "\n",
    "    part = np.asarray((mean_nees, q975_nees, mean_err, q975_err)).T\n",
    "    part = to_df(part, columns=['nees_mean', 'nees_q975', 'err_mean', 'err_q975'])\n",
    "    part['Q'] = str(Q)\n",
    "    \n",
    "    data.append(part)\n",
    "\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a7218-adc5-491f-823e-cb7e5c76f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ex.box(data.melt(['Q'], ['nees_mean', 'nees_q975', 'err_mean', 'err_q975'], 'metric', 'value'),\n",
    "             x='Q', y='value', color='metric')\n",
    "\n",
    "ci = sp.stats.chi2.ppf([0.025, 0.975], run.m * nees.dim) / run.m\n",
    "fig.add_hline(y=ci[0], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_hline(y=ci[1], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90f4ce-a6a2-4520-914e-0be31d4e092a",
   "metadata": {},
   "source": [
    "As expected, only for $Q=0$, the mean NEES falls within the 95% confidence interval. However, it is also the value of $Q$ for which the 0.975 quantile of NEES is the highest, which is due to the accumulation of error within each independent run of the filter. This is also where the non-scaled error is the lowest, which means that in any given iterations of any individual run, we expect a very precision position estimate and a very imprecise covariance estimate.\n",
    "\n",
    "The 0.975 quantile of NEES falls within the 95% confidence interval for somewhere around $Q=2$. This is where, most of the time within a single run, we can trust that the actual error of the position estimate matches the reported esimate of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead08459-aa67-42aa-8cd0-cb180c4322d5",
   "metadata": {},
   "source": [
    "Let's now take one last look at boxplots of all of the NEES and error data: each individual boxplot will aggregate $100 \\times 400$ data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed654d-b5c9-4e16-bede-574be59b6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for Q in [0, .001, .002, .005, .01, .02, .05, .1, .2, .5, 1, 1.5, 2, 2.5, 5, 10, 20]:\n",
    "    run  = _drift_many(Q)\n",
    "    nees = evaluate_nees(run.many_x_hat[:, 100:, :3, :], run.many_P_hat[:, 100:, :3, :3], run.truth[101:, :3])\n",
    "    err  = np.linalg.norm(run.many_x_hat[:,100:,:3,0] - run.truth[101:,:3], axis=2)\n",
    "    \n",
    "    part = np.asarray((nees.scores.reshape(-1), err.reshape(-1))).T\n",
    "    part = to_df(part, columns=['nees', 'err'])\n",
    "    part['Q'] = str(Q)\n",
    "    \n",
    "    data.append(part)\n",
    "\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94918362-be46-4a6e-8847-0c7d582f20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ex.box(data.melt(['Q'], ['nees', 'err'], 'metric', 'value'), x='Q', y='value', color='metric')\n",
    "fig.update_traces(boxpoints=False)\n",
    "\n",
    "ci = sp.stats.chi2.ppf([0.025, 0.975], run.m * nees.dim) / run.m\n",
    "fig.add_hline(y=ci[0], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_hline(y=ci[1], line_width=.5, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde037e1-ef03-42b8-819e-bd9f91aec811",
   "metadata": {},
   "source": [
    "# Multiple independent runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b53db-57cb-4270-8c93-3d398d9a688a",
   "metadata": {},
   "source": [
    "## NEES statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed0ad6-f93a-4f23-972f-f2da8f4503ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motion = ConstantVelocityModel(0)\n",
    "kf = LinearKalmanFilter(motion, [[1, 0, 0, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0, 0, 0],\n",
    "                                 [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "cv0 = run_many(100, 400, target, sensor, kf)\n",
    "cv0_eval = evaluate_many(*cv0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2e9e7-e8bc-455c-aecd-0c2380a5de0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_nees(cv0_eval.position_nees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f54dd-1909-4fa6-8b50-daf0aa69cf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motion = ConstantVelocityModel(1)\n",
    "kf = LinearKalmanFilter(motion, [[1, 0, 0, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0, 0, 0],\n",
    "                                 [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "cv1 = run_many(100, 400, target, sensor, kf)\n",
    "cv1_eval = evaluate_many(*cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2c62b-b843-4f71-b8f4-98ec60c085c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_nees(cv1_eval.position_nees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339807a-fb65-4b08-b2b2-8978e9978e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motion = ConstantVelocityModel(3)\n",
    "kf = LinearKalmanFilter(motion, [[1, 0, 0, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0, 0, 0],\n",
    "                                 [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "cv3 = run_many(100, 400, target, sensor, kf)\n",
    "cv3_eval = evaluate_many(*cv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c15cea-c718-4d1a-a8e9-5b7c102f746a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_nees(cv3_eval.position_nees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1376f-ed12-4fe9-b71e-31f191f08665",
   "metadata": {},
   "source": [
    "## All individual runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffdc6d-715b-4479-af1b-b4bc8bad257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(cv0_eval.position_nees.scores.shape[0]):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(375), y=cv0_eval.position_nees.scores[i,25:], mode='lines', legendgroup=i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07961a-e609-4745-bc1e-f379d5efbaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(cv1_eval.position_nees.scores.shape[0]):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(375), y=cv1_eval.position_nees.scores[i,25:], mode='lines', legendgroup=i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176b677-27be-436f-9092-b3860ab66013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(cv3_eval.position_nees.scores.shape[0]):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(375), y=cv3_eval.position_nees.scores[i,25:], mode='lines', legendgroup=i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfae215-e699-4fb4-b99c-8b8393584e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
